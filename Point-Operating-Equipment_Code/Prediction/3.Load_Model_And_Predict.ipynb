{"cells":[{"cell_type":"markdown","source":["##### Loading model and Prediction."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f46f8801-a3af-4a8c-ac8c-11aaac807b35"}}},{"cell_type":"code","source":["def predictions_at_trace_level(Asset_list,Raw_data_path,RN,NR,features_to_test,model_path):\n  \n  '''This function loads the trained random forest model which is in .sav format and then gives predictions as 0 or 1 for every trace, 0 being               anomalous and 1 being Normal\n  \n  Input :: Pandas dataframe containing all seven features for all the traces and trained random forest model\n  Output :: Pandas dataframe containing the predictions of random forest against all the traces either 0 or 1'''\n  \n  Feature_pdf = create_features(Asset_list,Raw_data_path,RN,NR)\n  ### calling create_feature function from the previous notebook\n  \n  Test_data = Feature_pdf.copy()\n  Test_data = Test_data[features_to_test]\n  #### Selecting the features on which the predictions will be made.\n  \n  loaded_model=pickle.load(open(model_path,'rb'))\n  #### Loading the trained random forest model.\n  \n  predictions = loaded_model.predict(Test_data)\n  #### Predicting on the features using the trained model\n  \n  Feature_pdf['forest_Predictions'] = predictions.tolist()\n  ### Storing the predictions from random forest model\n  \n  Feature_pdf['TraceNum'] = Feature_pdf['TraceNum'].astype('float')\n  Feature_pdf['TraceDir_New'] = Feature_pdf['TraceDir_New'].astype('float')\n  Feature_pdf['forest_Predictions'] = Feature_pdf['forest_Predictions'].astype('float')\n  #### Converting datatype to float\n  \n  model_result = Feature_pdf[['Name', 'DATE', 'TraceDir', 'TraceNum', 'TimeStamp', 'Trace_Start_Time','forest_Predictions']]\n  #### Selecting the relevant columns only\n  \n  model_result = model_result.sort_values(['Name','Trace_Start_Time'])\n  #### Sorting the data on Name and Trace Start Time\n  \n  return model_result"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6aa6ac1e-17cf-4e76-9d22-e9aad00b92e8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"3.Load_Model_And_Predict","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2700526048032577}},"nbformat":4,"nbformat_minor":0}
