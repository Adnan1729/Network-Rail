{"cells":[{"cell_type":"markdown","source":["##### Running post processing steps and getting final output."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d0c3f6c-3e96-43e3-9b9b-c888c4040f92"}}},{"cell_type":"code","source":["def final_output(Asset_list,Raw_data_path,RN,NR,features_to_test,model_path,Anomaly_threshold,alpha,beta,low_pass_filter_threshold):\n  \n  '''This function loads the day level predictions based on anomaly percentage and then applies a low pass filter which takes previous two days               predictions to finally mark a date as anomalous or normal. It has two parameter alpha for previous day and beta for day before previous day\n  \n  Input :: 1. Pandas dataframe containing the aggregated predictions of Random forest at day level and  prediction based on Anomaly threshold.\n            2. alpha -- This is the lag1 which takes the previous day's prediction\n            3. beta --  This  is the lag2 which takes the day before previous day's prediction\n            4. low_pass_filter_threshold -- This is the final threshold which marks a day level data as anomalous or normal\n            \n  Output :: Pandas dataframe containing the final result at day level'''\n  \n  Result_df_final = day_level_result(Asset_list,Raw_data_path,RN,NR,features_to_test,model_path,Anomaly_threshold)\n  ## Calling the day_level_result function from the previous file\n  \n  new_df_lag2 = pd.DataFrame()\n  ## Creating empty dataframe to store the final results after applying low pass filter\n  \n  assets = Result_df_final['Name'].unique()\n  ## Extracting the names of the assets\n  \n  \n  for a in assets:\n    df_group_lag2 = Result_df_final[Result_df_final.Name==a]\n    ### Selecting a particular asset's data\n    df_group_lag2 = df_group_lag2.sort_values(by='DATE')\n    index_list_lag2 = df_group_lag2.index.values.tolist()\n    df_group_lag2.loc[index_list_lag2[0], 'new_y_hat'] = df_group_lag2.loc[index_list_lag2[0], 'y']\n    df_group_lag2.loc[index_list_lag2[1], 'new_y_hat'] = df_group_lag2.loc[index_list_lag2[1], 'y']\n    \n    \n    #### Storing first two days predictions\n    for i in range(2, len(df_group_lag2)):\n      ## Iterating through each prediction for this asset\n      \n      \n      df_group_lag2.loc[index_list_lag2[i], 'new_y_hat'] = df_group_lag2.loc[index_list_lag2[i-1], 'new_y_hat'] + alpha*(df_group_lag2.loc[index_list_lag2[i], 'y'] - df_group_lag2.loc[index_list_lag2[i-1], 'new_y_hat']) + beta*(df_group_lag2.loc[index_list_lag2[i], 'y'] - df_group_lag2.loc[index_list_lag2[i-2], 'new_y_hat'])\n      ### This is the low pass fiter formula where alpha and beta are the weights given to the predictions of previous day and the day before previous           day respectively. \n      \n    new_df_lag2 = new_df_lag2.append(df_group_lag2)\n    ## Saving the low pass result\n    \n  new_df_lag2['final_prediction'] = new_df_lag2['new_y_hat'].apply(lambda x : -1 if x>=low_pass_filter_threshold   else 1)\n  #### creating final predicting predictions where 0 represents that the day has been marked as anomalous and 1 means the day has been marked as normal\n  \n  Final_result = new_df_lag2[['Name','DATE','final_prediction']]\n  ## Selecting the relevant columns\n  \n  return Final_result"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f79c53f3-a4b3-43d1-84c5-259242a3c596"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["Final_result = final_output(Asset_list,Raw_data_path,RN,NR,features_to_test,model_path,Anomaly_threshold,alpha,beta,low_pass_filter_threshold)\nFinal_result.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ee9973c-7fb8-4683-9dfe-d88df010be4b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["Final_result.to_csv(result_path,index = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8feff77a-f912-4e27-bdf5-d2c2f769e455"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"5.Post_Processing_And_Final_Result","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2700526048032580}},"nbformat":4,"nbformat_minor":0}
